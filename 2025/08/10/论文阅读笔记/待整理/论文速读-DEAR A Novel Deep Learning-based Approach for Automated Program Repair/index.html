<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>论文速读-DEAR A Novel Deep Learning-based Approach for Automated Program Repair | 随笔</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="论文基本情况： 论文名：DEAR: A Novel Deep Learning-based Approach for Automated Program Repair  作者：Yi Li(New Jersey Inst. of Technology), Shaohua Wang(University of Waterlor), Tien N. Nguyen(University of Texas">
<meta property="og:type" content="article">
<meta property="og:title" content="论文速读-DEAR A Novel Deep Learning-based Approach for Automated Program Repair">
<meta property="og:url" content="http://example.com/2025/08/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E5%BE%85%E6%95%B4%E7%90%86/%E8%AE%BA%E6%96%87%E9%80%9F%E8%AF%BB-DEAR%20A%20Novel%20Deep%20Learning-based%20Approach%20for%20Automated%20Program%20Repair/index.html">
<meta property="og:site_name" content="随笔">
<meta property="og:description" content="论文基本情况： 论文名：DEAR: A Novel Deep Learning-based Approach for Automated Program Repair  作者：Yi Li(New Jersey Inst. of Technology), Shaohua Wang(University of Waterlor), Tien N. Nguyen(University of Texas">
<meta property="og:locale">
<meta property="article:published_time" content="2025-08-10T14:08:05.509Z">
<meta property="article:modified_time" content="2025-08-10T14:10:59.151Z">
<meta property="article:author" content="水与酒精与咖啡因">
<meta name="twitter:card" content="summary">
  
    <link rel="alternate" href="/atom.xml" title="随笔" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/fork-awesome@1.2.0/css/fork-awesome.min.css">

<meta name="generator" content="Hexo 7.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">随笔</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">学习过程中的一点记录以及生活分享</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Suche"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Suche"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-论文阅读笔记/待整理/论文速读-DEAR A Novel Deep Learning-based Approach for Automated Program Repair" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2025/08/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E5%BE%85%E6%95%B4%E7%90%86/%E8%AE%BA%E6%96%87%E9%80%9F%E8%AF%BB-DEAR%20A%20Novel%20Deep%20Learning-based%20Approach%20for%20Automated%20Program%20Repair/" class="article-date">
  <time class="dt-published" datetime="2025-08-10T14:08:05.509Z" itemprop="datePublished">2025-08-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      论文速读-DEAR A Novel Deep Learning-based Approach for Automated Program Repair
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="论文基本情况："><a href="#论文基本情况：" class="headerlink" title="论文基本情况："></a>论文基本情况：</h1><blockquote>
<h2 id="论文名：DEAR-A-Novel-Deep-Learning-based-Approach-for-Automated-Program-Repair"><a href="#论文名：DEAR-A-Novel-Deep-Learning-based-Approach-for-Automated-Program-Repair" class="headerlink" title="论文名：DEAR: A Novel Deep Learning-based Approach for Automated Program Repair"></a><strong>论文名</strong>：DEAR: A Novel Deep Learning-based Approach for Automated Program Repair</h2></blockquote>
<blockquote>
<h2 id="作者：Yi-Li-New-Jersey-Inst-of-Technology-Shaohua-Wang-University-of-Waterlor-Tien-N-Nguyen-University-of-Texas-at-Dallas"><a href="#作者：Yi-Li-New-Jersey-Inst-of-Technology-Shaohua-Wang-University-of-Waterlor-Tien-N-Nguyen-University-of-Texas-at-Dallas" class="headerlink" title="作者：Yi Li(New Jersey Inst. of Technology), Shaohua Wang(University of Waterlor), Tien N. Nguyen(University of Texas at Dallas)"></a><strong>作者</strong>：Yi Li(New Jersey Inst. of Technology), Shaohua Wang(University of Waterlor), Tien N. Nguyen(University of Texas at Dallas)</h2></blockquote>
<blockquote>
<h2 id="来源：2022-ICSE"><a href="#来源：2022-ICSE" class="headerlink" title="来源：2022 ICSE"></a><strong>来源</strong>：2022 ICSE</h2></blockquote>
<blockquote>
<h2 id="论文主题：漏洞修复，-Software-maintenance-tools"><a href="#论文主题：漏洞修复，-Software-maintenance-tools" class="headerlink" title="论文主题：漏洞修复， Software maintenance tools"></a><strong>论文主题</strong>：漏洞修复， Software maintenance tools</h2></blockquote>
<h1 id="论文阅读"><a href="#论文阅读" class="headerlink" title="论文阅读"></a>论文阅读</h1><p>这一篇也是在ICSE上发的，跟之前的CURE一样。所以说，这方面的研究还是主要集中在软工领域？毕竟安全四大也看了一些，但漏洞修复相关的内容看到的还是比较少，之后可以多注意一下软工的会。<br>题目上看不出有什么新意，属于是比较简单、朴素的题目了。<br>开门见山，一句简单的背景后，直接说明了本文方法的核心，能够修复一行或多行的漏洞，这个跟之前看到的一些都不一样。DEAR中包含了一个漏洞定位的功能，这也支持了多行的修复。结合传统的基于谱频的定位方法与深度学习模型来进行定位，具体的定位方法目前没有看太懂。而修复方面，设计了两层基于树的LSTM模型，这个模型结构之后可以参考一下，使用“分而治之”的策略来学习正确的代码转换，这个“分而治之”之后应该需要多注意一下。再之后就是修复效果的说明，牛就完事了。</p>
<p>Introduction部分开头写的比较直接，可能还是方法比较硬。介绍了现有的方法，基于搜索的，软件挖掘和修复模式学习，机器学习结合软件挖掘，还有一些基于DL的方法。这些东西写的非常简洁，两段所有的事情就说完了。再之后对基于DL的方法的缺陷进行分析。对一般缺陷存在限制，这些缺陷一般需要对多行进行修改。但这个实际上是有局限的（虽然上一篇论文也是针对一行代码做的），这种模式限制了这一类方法的进步。<br>本文的方法支持一次性修复属于一个或多个错误代码块的一个或多个错误语句的依赖更改的一般错误。</p>
<ol>
<li>多块多行漏洞定位技术。SBFL来识别可疑语句的列表，再把这些内容输入到微调后的BERT中，得到需要一起修复的错误块。还对块中的错误语句作为种子，通过RNN进行错误分类，通过数据流分析进行调整，最终得到错误块。方法很复杂，确实很牛逼。</li>
<li>得到漏洞分布后，用分治策略来学习AST中的每个字数的转换，来学习细粒度的变化和修复的映射。</li>
<li>两层的模型结构，结合注意力层和循环训练，对于定位出每个有漏洞的子树，编码为向量，第一层学习修复上下文，下一层以上下文为权重来修复有缺陷的子树。这个实际上跟CURE有点类似，CURE的encoder有两个，一个学bug，一个学上下文。</li>
<li>最后，对子树进行修复，修复后的子树代表了正确的代码。<br>但最后贡献部分写的不是很舒服，格式很乱。</li>
</ol>
<p>Motivation部分作为第二章，通过一个例子进行说明。但问题在于斜体字用的很乱，看的不是很舒服。<br>下面对于其他方法的分析实际上有些不是很认同，之前的方法只假定某一行出问题，其他行均正确，按文中的说法仍然无法通过测试样例。但之前的研究同样有一个假设或者说设定，修复并不是指不存在任何漏洞，而是较修复前的代码能通过更多的测试样例。而没有一种方法能保证修复后的程序不会有任何问题。话虽这么说，一次能将所有已知的漏洞都修复完成肯定更好。<br>而且，仔细想一想，图一的例子，第5行和第10行实际上属于两个漏洞，逻辑上还是有点不太顺。<br>这个思路之前确实也想过，但没这么细致。将代码转化为语法树，对语法树进行修改和调整，修复结束后再转化为代码，这样实际上也实现了多行的修复—-因为语法树的修改结果可能反映到多行上。<br>但对于分的点，不是很清楚，<strong>为什么把子树的转化和修复上下文分成两部分</strong>，可能后面会有答案。这是一个点，另一个点在于 <strong>dependent fixing changes</strong>和<strong>dependently changed together</strong> 这些都是什么意思</p>
<p>在下面2.2 对上面的几点做了更详细的说明。定位上，先用SBFL给出所有可能的缺陷位置，并包含怀疑度。之后，首先用深度学习模型来检测其他相邻的代码是否需要跟某一行一起修复。因为SBFL只会返回可疑的候选位置，但不一定会一起修复。其次，设计了一个扩展算法，将可疑的语句所再的块组合在一起。需要看下代码和后面的内容，目前的理解是SBFL定位，先用模型决定定位出的漏洞是单行还是多行，最后，将所有的块组合到一起，确定所有需要修复的部分。<br>一块对应了一个子树，对应一个bug，分别使用模型进行处理。使用了一个变更检测模型来对应修复前后的变化。这个在其他的方案中应该是没有的，因为DEAR应用于多行多漏洞，可能修复前是3行，修复后变成了5行，而且还不止一个漏洞，因此可能会出现修复a的漏洞，放到了b的位置。但逐个修复不能处理吗？分而治之的思路实际上也是这么个流程<br>实际上貌似也是这么做的？<del>两层的模型一次只修复一个子树</del>第一层，将有bug的子树，用一个伪节点占位，新的AST作为修复的上下文。这个伪节点是通过嵌入技术计算出的。第二层负责生成任务，学习bug到补丁的转变（可能是n行到m行）。第一层得出的修复上下文向量作为第二层的权重，对每个有bug的子树重复相同的过程。一次对所有的语句都执行。</p>
<p>最核心部分 方法概述<br>训练流程：输入是修复前代码，输出两个模型，一个上下文模型，另一个树转换模型。前者学习权重，代表上下文的影响，对树变换的结果进行调整；后者学习代码转化，负责修复任务。	<br>上下文学习：先构建训练数据，用CPatMiner负责对子树的处理。错误语句的AST子树被映射到各自的修复子树，并进行学习；树转换学习：同样是用CPatMiner导出子树映射，错误子树与对应的修复子树在第二个模型进行训练。还是没搞明白这两个模型的区别在哪里，感觉第一个模型就已经实现了修复代码的生成？第二个模型的作用不是很明显，感觉就是跑了两遍，另一个角度，思考一下，是不是跟CURE是一种？训练的数据还是有一点不同？<br>修复流程：先错误定位，再将连续的错误代码组合起来，对有缺陷的子树，输入上下文模型CTL中，产生权重，在输入树转换模型TTL，产生修复子树，最后用语法规则和程序分析产生修复代码，验证方法与DLFix相同</p>
<p>训练过程</p>
<ol>
<li>构建bug和修复代码：<ol>
<li>如果子树对应一条语句，则称为statement subtree。根据CPatMiner的结果，对应的规则如下：<ol>
<li>bug子树（S-subtree）分为两类：更新或删除的子树；</li>
<li>如果是删除子树，则与空树对应，也就是没有对应的修复代码；</li>
<li>如果是更新（子树更新或子节点插入删除更改），将bug子树和修复子树成对；</li>
<li>如果插入了一个子树，且父节点是另一个子树，将被插入的子树与父节点匹配，如果父节点不是S-subtree，则与空子树对应</li>
</ol>
</li>
<li>不清楚的是，每个子树的构建规则是什么？也就是哪些语句转化成的子树</li>
</ol>
</li>
<li>上下文构建：有一组对应的bugAST$I_1$和修复AST$O_1$ <ol>
<li>第一步：对每个节点，转化成词向量（GloVe）–语句节点看一个句子，每个标记作为单词，得到向量化的结果$I_2$和$O_2$</li>
<li>对bugAST和修复AST中对应的子树 $T_b$和$T_f$逐一处理。首先，用TreeCaps对$T_b$和$T_f$分别汇总，记录树结构到$V_s$和$V_s^{‘}$。其次，对于其他的所有bug子树 $T_b^{‘}$和对应的修复字数 $T_f^{‘}$，用$T_f^{‘}$替换$T_b^{‘}$来构建上下文$I_3$，为了保持正确的上下文信息，在$O_3$中保留$T_f^{‘}$。这一部分有点看不懂了又…问题在于$T_b$和 $T_b^{‘}$是什么关系？为什么要互相替代</li>
<li>$I_3$作为有缺陷的修复前上下文，并用于CTL编码器的输入层的学习，$O_3$作为修复后上下文，用于解码器的输出层。</li>
</ol>
</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2025/08/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E5%BE%85%E6%95%B4%E7%90%86/%E8%AE%BA%E6%96%87%E9%80%9F%E8%AF%BB-DEAR%20A%20Novel%20Deep%20Learning-based%20Approach%20for%20Automated%20Program%20Repair/" data-id="cme5ri1i30001qodjghk4hibo" data-title="论文速读-DEAR A Novel Deep Learning-based Approach for Automated Program Repair" class="article-share-link"><span class="fa fa-share">Teilen</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2025/08/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E5%BE%85%E6%95%B4%E7%90%86/CURE%20Code-Aware%20Neural%20Machine%20Translation%20for%20Automatic%20Program%20Repair/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Älter</strong>
      <div class="article-nav-title">CURE Code-Aware Neural Machine Translation for Automatic Program Repair</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archiv</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/08/">August 2025</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">letzter Beitrag</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/08/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E5%BE%85%E6%95%B4%E7%90%86/%E8%AE%BA%E6%96%87%E9%80%9F%E8%AF%BB-DEAR%20A%20Novel%20Deep%20Learning-based%20Approach%20for%20Automated%20Program%20Repair/">论文速读-DEAR A Novel Deep Learning-based Approach for Automated Program Repair</a>
          </li>
        
          <li>
            <a href="/2025/08/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E5%BE%85%E6%95%B4%E7%90%86/CURE%20Code-Aware%20Neural%20Machine%20Translation%20for%20Automatic%20Program%20Repair/">CURE Code-Aware Neural Machine Translation for Automatic Program Repair</a>
          </li>
        
          <li>
            <a href="/2025/08/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E5%BE%85%E6%95%B4%E7%90%86/Defending%20Pre-trained%20Language%20Models%20from%20Adversarial%20Word%20Substitution%20Without%20Performance%20Sacrifice/">第一篇-测试</a>
          </li>
        
          <li>
            <a href="/2025/08/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0/%E5%BE%85%E6%95%B4%E7%90%86/Virtual%20Adversarial%20Training%20A%20Regularization%20Method%20for%20Supervised%20and%20Semi-Supervised%20Learning/">第一篇-测试</a>
          </li>
        
          <li>
            <a href="/2025/08/03/GitHub%20Pages%20+%20Hexo%20%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/">GitHub Pages + Hexo 搭建个人博客</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2025 水与酒精与咖啡因<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>